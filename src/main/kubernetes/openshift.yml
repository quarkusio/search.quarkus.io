---
apiVersion: v1
kind: Service
metadata:
  name: search-backend
  labels:
    app: search-backend
    app.kubernetes.io/name: search-backend
    app.kubernetes.io/component: datastore
    app.kubernetes.io/part-of: search-quarkus-io
    app.kubernetes.io/version: {{ .Values.app.version }}
spec:
  ports:
    - name: http
      port: 9200
      protocol: TCP
    - name: inter-node
      protocol: TCP
      port: 9300
  selector:
    app.kubernetes.io/name: search-backend
  type: ClusterIP
  # Using a StatefulSet, each pod has its own immutable address,
  # so we don't need the service to have an IP.
  clusterIP: None
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: search-backend
  labels:
    app: search-backend
    app.kubernetes.io/name: search-backend
    app.kubernetes.io/component: datastore
    app.kubernetes.io/part-of: search-quarkus-io
    app.kubernetes.io/version: {{ .Values.app.version }}
# See https://www.hafifbilgiler.com/hafif-bilgiler/elasticsearch-installation-on-openshift/
spec:
  serviceName: search-backend
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: search-backend
  template:
    metadata:
      labels:
        app: search-backend
        app.kubernetes.io/name: search-backend
        app.kubernetes.io/component: datastore
        app.kubernetes.io/part-of: search-quarkus-io
      annotations:
        alpha.image.policy.openshift.io/resolve-names: '*'
    spec:
      containers:
        - name: opensearch
          # The image gets pushed manually as part of the "deploy" workflow.
          # This gets replaced with the correct image ref (exact tag).
          image: opensearch-custom:latest
          imagePullPolicy: Always
          resources:
            limits:
              cpu: '{{ .Values.opensearch.resources.limits.cpu }}'
              memory: '{{ .Values.opensearch.resources.limits.memory }}'
            requests:
              cpu: '{{ .Values.opensearch.resources.requests.cpu }}'
              memory: '{{ .Values.opensearch.resources.requests.memory }}'
          readinessProbe:
            httpGet:
              scheme: HTTP
              path: /_cluster/health?local=true
              port: 9200
            initialDelaySeconds: 5
          ports:
            - name: http
              containerPort: 9200
              protocol: TCP
            - name: inter-node
              containerPort: 9300
              protocol: TCP
          volumeMounts:
            - name: data
              mountPath: /usr/share/opensearch/data
          env:
            - name: cluster.name
              value: search-quarkus-io
            - name: node.name
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            # We don't have enough nodes/memory available in the cluster to allow for 3 decently-sized pods,
            # and 3 pods with low memory perform badly, so we'll have to make do with a single pod.
            - name: discovery.type
              value: "single-node"
            # Memory locking doesn't work on our OpenShift instance,
            # but this shouldn't be too bad as we don't expect swapping to be enabled.
            - name: bootstrap.memory_lock
              value: "false"
            # OpenSearch doesn't seem to automatically adapt -Xmx to available memory, for some reason
            - name: OPENSEARCH_JAVA_OPTS
              value: '{{ .Values.opensearch.envs.OPENSEARCH_JAVA_OPTS }}'
            # This is necessary to avoid OpenSearch trying to install various things on startup,
            # which leads to filesystem operations (chmod/chown) that won't work
            # because only user 1000 has the relevant permissions,
            # and we can't run with user 1000 on OpenShift.
            # See also:
            # - https://github.com/opensearch-project/opensearch-devops/issues/97
            # - src/main/docker/opensearch-custom.Dockerfile
            - name: DISABLE_PERFORMANCE_ANALYZER_AGENT_CLI
              value: 'true'
            - name: DISABLE_INSTALL_DEMO_CONFIG
              value: 'true'
            # Not exposed to the internet, no sensitive data
            # => We don't bother with HTTPS and pesky self-signed certificates
            # Setting this env variable is better than setting plugins.security.disabled
            # because this skips installing the plugin altogether (see above)
            - name: DISABLE_SECURITY_PLUGIN
              value: 'true'
          envFrom:
            - configMapRef:
                name: search-backend-config
            - secretRef:
                name: search-backend-secrets
  volumeClaimTemplates:
    - metadata:
        name: data
        labels:
          app: search-backend
          app.kubernetes.io/name: search-backend
          app.kubernetes.io/component: datastore
          app.kubernetes.io/part-of: search-quarkus-io
      spec:
        accessModes: [ "ReadWriteOnce" ]
        storageClassName: "gp2"
        resources:
          requests:
            storage: 5Gi